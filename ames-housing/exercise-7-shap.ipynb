{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Step-by-step - Exercise 7 - Exercise\n",
    "\n",
    "## Use SHAP values to explain how features contribute to Sale Price prediction\n",
    "\n",
    "Pieter Overdevest  \n",
    "2024-11-07\n",
    "\n",
    "For suggestions/questions regarding this notebook, please contact\n",
    "[Pieter Overdevest](https://www.linkedin.com/in/pieteroverdevest/)\n",
    "(pieter@innovatewithdata.nl).\n",
    "\n",
    "### How to work with this Jupyter Notebook yourself?\n",
    "\n",
    "- Get a copy of the repository [discover-projects/ames-housing](https://github.com/EAISI/discover-projects/tree/main/ames-housing) from EAISI's GitHub site. This can be done by either cloning the repo or simply by downloading the zip-file. Both options are explained in this Youtube video by [Coderama](https://www.youtube.com/watch?v=EhxPBMQFCaI). This exercise builds on the six exercises presented in the README file in the Ames Housing folder in this repo.\n",
    "\n",
    "- Copy this notebook to your own project folder. I suggest to work in a copy of this notebook and not in the downloaded notebook itself. This way it is clear what files you work with and you can keep the original notebook for reference.\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this exercise we predict the sale price by using a Random Forest model - as example of a blackbox model - with k-fold cross-validation and grid search on a small set of hyperparameters. The latter part was added to show you another example how to apply cross-validation and hyperparameter optimization.\n",
    "\n",
    "This seventh exercise literally builds on the six exercises for the [Ames Housing case](https://github.com/EAISI/discover-projects/tree/main/ames-housing), as it uses the cleaned/imputed data prepared in those exercises.\n",
    "\n",
    "A solution of this exercise can be found in 'ames-housing-pieter-execise-7-shap-solution.ipynb' in the folder '/discover-project-example/pieterov/' in repo [introduction-track-for-participants](https://github.com/EAISI/introduction-track-for-participants) from EAISI's GitHub site. \n",
    "\n",
    "\n",
    "### Use of ChatGPT, Cody, Copilot, ..\n",
    "\n",
    "In case you want to use platforms like ChatGPT, Cody, or Copilot, here are some suggestions to enter:\n",
    "\n",
    "* How to import random forrest regression model in python?\n",
    "* What hyperparameters do I have access to in this model?\n",
    "* Can you suggest a dictionary with some common ranges to use with these hyperparameters?\n",
    "* How to use this model in conjunction with gridsearchcv?\n",
    "\n",
    "Of course, these questions are already quite specific and when you start your questions might be more generic, like \"How do I do check the performance on a range of hyperparameters\". These examples show that also as you develop your knowledge, the likes of ChatGPT remain a good source for suggesting snippets of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party packages.\n",
    "import pickle   # Save and load data\n",
    "import shap     # Explain the model (SHAP)\n",
    "\n",
    "# Import module.\n",
    "from sklearn.ensemble           import RandomForestRegressor    # Random forest\n",
    "from sklearn.model_selection    import GridSearchCV             # Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two routes to proceed with this exercise\n",
    "\n",
    "**Route 1** - You proceed with the notebook(s) that you developed for exercises 1-6. You copy the code snippets below to your notebook(s). Then, you use your own processed data.\n",
    "\n",
    "**Route 2** - You proceed with this Jupyter Notebook. Copy 'dc-ames-housing-pieter-exercise-5-6.pkl' to the same folder where you stored a copy of this notebook. You can find this so-called 'pickled' file in the folder '/discover-project-example/pieterov/data/' in repo [introduction-track-for-participants](https://github.com/EAISI/introduction-track-for-participants) on EAISI's GitHub site. Then, you load the pickled file in this notebook using the code below.\n",
    "\n",
    "### Load objects from earlier exercises in case you follow route 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dc-ames-housing-pieter-exercise-5-6.pkl', 'rb') as pickle_file:\n",
    "    dc_exercise_1_2_3 = pickle.load(pickle_file)\n",
    "\n",
    "df_X_train_scaled = dc_exercise_1_2_3['df_X_train_scaled']\n",
    "ps_y_log_train    = dc_exercise_1_2_3['ps_y_log_train']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A - Construct a data frame holding the imputed numerical data of the Ames Housing data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, the SHAP calculations are computer intensive, take the first 500 observations from the training set (call it, `df_X_fraction`) and take the first 500 elements of the outcome variable from the resulting training set (call it, `ps_y_fraction`). Note, we omit the train/test split, since the purpose of this exercise is to demonstrate the use of SHAP values.\n",
    "\n",
    "Optionally, include the one-hot-encoded neighborhoods feature, by running either scenario A or B in Exercise 5.3b, see solution notebook 'ames-housing-pieter-exercise-5-6.ipynb' in folder '\\discover-project-examples\\pieterov'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B - Run or copy/paste the content from the cell below to your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid:\n",
    "dc_hyperparameter_ranges = {\n",
    "\n",
    "    'bootstrap':            [True,False],   # Do we bootstrap samples, or not.\n",
    "    'max_depth':            [20],           # Maximum depth of each tree\n",
    "    'max_features':         ['sqrt'],       # Number of features to consider at each split (options: 'auto', 'sqrt')\n",
    "    'min_samples_leaf':     [4],            # Minimum number of samples required to be at a leaf node\n",
    "    'min_samples_split':    [4],            # Minimum number of samples required to split an internal node\n",
    "    'n_estimators':         [1000],         # Number of trees\n",
    "    'random_state':         [42]            # Random state for reproducibility\n",
    "}\n",
    "\n",
    "# Perform a gridsearch on the random forest model:\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator  = RandomForestRegressor(),\n",
    "    param_grid = dc_hyperparameter_ranges,\n",
    "    scoring    = 'neg_mean_squared_error',\n",
    "    cv         = 5\n",
    ")\n",
    "\n",
    "# Use subset of training data to do a gridsearch on the random forest model:\n",
    "gridsearch.fit(df_X_fraction, ps_y_fraction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise C - Show the value of the `best_params` attribute of the `gridsearch` object. What do the attributes `best_params_` and `best_estimator_` refer to? Assign the value of the `best_estimator_` attribute to a new object called, `best_model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameter set from the set given in `dc_hyperparameter_ranges` is captured in the attribute `best_params_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model is captured in the attribute `best_estimator_`. So, we do not need to rerun the model with the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise D - Run copy/paste the content from the cell below to your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize JavaScript visualization support for SHAP (SHapley Additive exPlanations) plots. \n",
    "shap.initjs()\n",
    "\n",
    "# Create SHAP object.\n",
    "explainer = shap.Explainer(best_model)\n",
    "\n",
    "# Create SHAP values.\n",
    "shap_values = explainer.shap_values(df_X_fraction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy/paste also the code in the cell below to your notebook and add missing pieces as requested in the exercises."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise E - Waterfall Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `waterfall plot` to visualise the SHAP values for a single observation. Run or copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Define an object to which you assign the index of the data point you want to explain the prediction for. Assign the value to your object such that you can explain the prediction for the second observation in the data.\n",
    "\n",
    "2 - Replace '...' by the object name you defined above.\n",
    "\n",
    "3 - What is the value for explainer.expected_value[0]?\n",
    "\n",
    "4 - Run the cell.\n",
    "\n",
    "5 - What do you conclude from the resulting figure? Use: (1) the answer from question 3 and (2) the prediction for the second observation in the data.\n",
    "\n",
    "For reference see also [API Reference of SHAP module](https://shap.readthedocs.io/en/latest/generated/shap.plots.waterfall.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index of data point you want to explain the prediction for.\n",
    "\n",
    "\n",
    "# Plot waterfall\n",
    "shap.plots.waterfall(\n",
    "    \n",
    "    shap.Explanation(\n",
    "        base_values   = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        values        = shap_values[...],            # Subset of shap values.\n",
    "        data          = df_X_fraction.iloc[...],     # Subset of training data.\n",
    "        feature_names = df_X_fraction.columns        # Feature names.\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise F - Force Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to visualise the SHAP values is by using a force plot. You can think of this as a condensed waterfall plot. Run or copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - The force plot is a different representation of the waterfall plot. Apply the questions from exercise 1 to the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index of data point you want to explain the prediction for.\n",
    "\n",
    "\n",
    "# Plot Force Plot.\n",
    "shap.plots.force(\n",
    "\n",
    "    base_value    = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "    shap_values   = shap_values[...],          # SHAP values.\n",
    "    features      = df_X_fraction.iloc[...],   # Training data.\n",
    "    feature_names = df_X_fraction.columns        # Feature names.\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise G - Stacked Force Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waterfall and force plots are great for interpreting individual predictions. To understand how our model makes predictions in general we need to aggregate the SHAP values. One way to do this is by using a stacked-force plot. We can combine multiple force plots together to create a stacked force plot. We can pass all SHAP values in the force plot function, or we can limit it, as we will do here. Each individual force plot is now vertical and stacked side by side. Run or copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Show the SHAP values for the first 10 observations.\n",
    "\n",
    "2 - Set the dropdown at the top of the figure to 'original sample ordering' and to the left of the figure to 'f(x)'. Look up the SHAP values for the observation with index 1. How do they compare to the number in exercise E and F?\n",
    "\n",
    "3 - Set the dropdown at the top of the figure to 'sample order by output value'. What do you observe?\n",
    "\n",
    "4 - Set the dropdown at the top of the figure to 'Overall Qual' and to the left of the figure to 'Overall Qual effects'. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of indices of data point you want to explain the prediction for.\n",
    "\n",
    "\n",
    "# Plot stacked force plot.\n",
    "shap.plots.force(\n",
    "    \n",
    "        base_value    = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        shap_values   = shap_values[...],            # SHAP values.\n",
    "        features      = df_X_fraction[...],          # Training data.\n",
    "        feature_names = df_X_fraction.columns        # Feature names.\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise H - Mean SHAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next plot will tell us which variables are most important. For each variable, we calculate the mean SHAP value across all observations. Specifically, we take the mean of the absolute values as we do not want positive and negative values to offset each other. There is one bar for each variable. Run or copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Run the cell. What do you conclude from the resulting chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean SHAP.\n",
    "shap.plots.bar(\n",
    "\n",
    "    shap_values = shap.Explanation(\n",
    "        base_values   = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        values        = shap_values,                 # Subset of shap values.\n",
    "        data          = df_X_fraction,               # Subset of training data.\n",
    "        feature_names = df_X_fraction.columns        # Feature names.\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise I - Beeswarm Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have the single most useful plot for interpretation of the overall model. The beeswarm visualises all of the SHAP values. Run or copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Run the cell. What do you conclude from the resulting chart?\n",
    "\n",
    "2 - In particular, what do you observe for 'Overall Qual'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot beeswarm plot.\n",
    "shap.plots.beeswarm(\n",
    "    \n",
    "    shap.Explanation(\n",
    "        base_values   = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        values        = shap_values,                 # SHAP values.\n",
    "        data          = df_X_fraction,               # Training data.\n",
    "        feature_names = df_X_fraction.columns        # Feature names.\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebb0a02d86bd6cc81bd76bc6c4cba297e0e4bde90b1df44b0c10ac2ad7a9009a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
